{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e09f930",
   "metadata": {
    "id": "818646af"
   },
   "source": [
    "# Modeling\n",
    "\n",
    "This notebook combines the three cleaned datasets into one central location and aggregates them before conducting data engineering and running a wide array of models to determine the final top performer and understand the relationships between the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eea982",
   "metadata": {
    "id": "9ba85793"
   },
   "source": [
    "## Data Imporrts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5943be64",
   "metadata": {
    "id": "8b5bb73c"
   },
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Importing databases using SQL\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Model preprocessing and processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Performance evaluation\n",
    "from sklearn.metrics import f1_score,precision_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# Data visualization\n",
    "import shap\n",
    "\n",
    "# Options\n",
    "#pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 200\n",
    "%matplotlib inline\n",
    "\n",
    "# Convenience for working with external src code files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "# Custom functions\n",
    "from create_target import *\n",
    "from remove_missing_data import *\n",
    "from evaluate_model_performance import *\n",
    "from custom_plots import *\n",
    "\n",
    "# Global constants\n",
    "RANDOM_STATE = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a80122",
   "metadata": {
    "id": "393ddbf1"
   },
   "source": [
    "##### Import \"Protests\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c52fce",
   "metadata": {
    "id": "fdd60fdd"
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../data/processed/protests.db')\n",
    "with engine.begin() as connection:\n",
    "    df_protests = pd.read_sql('SELECT * FROM protests', con=connection)\n",
    "\n",
    "# Type casting\n",
    "df_protests.startdate = pd.to_datetime(df_protests.startdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81efb618",
   "metadata": {
    "id": "768bda6c"
   },
   "source": [
    "##### Import \"Governments\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451f8840",
   "metadata": {
    "id": "712c9b25"
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../data/processed/governments.db')\n",
    "with engine.begin() as connection:\n",
    "    df_govts = pd.read_sql('SELECT * FROM governments', con=connection)\n",
    "\n",
    "# Set index to be used on Join later\n",
    "df_govts.index = df_govts.year_scode\n",
    "\n",
    "# Remove unused features\n",
    "df_govts.drop('year_scode', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a197833",
   "metadata": {
    "id": "feecd926"
   },
   "source": [
    "##### Join \"Protests\" and \"Governments\" datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "695f7c7a",
   "metadata": {
    "id": "8f56d152"
   },
   "outputs": [],
   "source": [
    "# Join both dataframes\n",
    "df = df_protests.join(df_govts, how='left', on='year_scode')\n",
    "\n",
    "# Remove entries that don't have corresponding 'government' data\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08b747e",
   "metadata": {
    "id": "68adfe35"
   },
   "source": [
    "##### Import \"Regime Changes\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c53544",
   "metadata": {
    "id": "7473f360",
    "outputId": "1c0d60ac-2556-48f1-86a9-7ae46e1446b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296 entries, 0 to 1295\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   country       1296 non-null   object        \n",
      " 1   scode         1296 non-null   object        \n",
      " 2   startdate     1296 non-null   datetime64[ns]\n",
      " 3   enddate       1296 non-null   datetime64[ns]\n",
      " 4   duration_yrs  1296 non-null   float64       \n",
      " 5   xconst        1296 non-null   int64         \n",
      "dtypes: datetime64[ns](2), float64(1), int64(1), object(2)\n",
      "memory usage: 60.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# IMPORT REGIME CHANGE DATASET\n",
    "engine = create_engine('sqlite:///../data/processed/regime_changes.db')\n",
    "with engine.begin() as connection:\n",
    "    df_regimes = pd.read_sql('SELECT * FROM regime_changes', con=connection)\n",
    "\n",
    "# Type conversions\n",
    "df_regimes.startdate = pd.to_datetime(df_regimes.startdate)\n",
    "df_regimes.enddate = pd.to_datetime(df_regimes.enddate)\n",
    "df_regimes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4bc91c",
   "metadata": {
    "id": "309fd063"
   },
   "source": [
    "##### QC that country names and country IDs match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2838dd47",
   "metadata": {
    "id": "e9fe039d",
    "outputId": "e404a394-1a3c-4650-efdf-e0b25a5f6641"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scode</th>\n",
       "      <th>scode_govt</th>\n",
       "      <th>country</th>\n",
       "      <th>country_govt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [scode, scode_govt, country, country_govt]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ['scode', 'scode_govt', 'country', 'country_govt']\n",
    "missing_countries = df.loc[(df.country != df.country_govt)][cols]\n",
    "missing_countries = missing_countries.drop_duplicates()\n",
    "display(missing_countries.sort_values(by='scode'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad931e",
   "metadata": {
    "id": "3c1bbefe"
   },
   "source": [
    "##### Remove countries that do not contain government data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "191e033a",
   "metadata": {
    "id": "2d33149d"
   },
   "outputs": [],
   "source": [
    "scodes_to_remove = missing_countries.scode.unique()\n",
    "scodes_to_remove_ind = [x in scodes_to_remove for x in df.scode]\n",
    "df.drop(df.loc[scodes_to_remove_ind].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eeeba3",
   "metadata": {
    "id": "13aafc6d"
   },
   "source": [
    "##### Identify countries that are missing from \"Regime Changes\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eac21407",
   "metadata": {
    "id": "fcc6d52f",
    "outputId": "9b33c1b8-65b3-49cd-a12d-169c825c3a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries missing from \"Regimes\" dataset: ['LUX']\n"
     ]
    }
   ],
   "source": [
    "# All countries in union of Protests and Governments\n",
    "all_countries = df.scode.unique()\n",
    "\n",
    "# All countries in Regimes\n",
    "regime_countries = df_regimes.scode.unique()\n",
    "\n",
    "\n",
    "# Loop over all_countries\n",
    "missing = []\n",
    "for country in all_countries:\n",
    "    # Make note of any countries not in Regimes\n",
    "    \n",
    "    if country not in regime_countries:\n",
    "        missing.append(country)\n",
    "\n",
    "print('Countries missing from \"Regimes\" dataset:', missing)\n",
    "\n",
    "# Remove these countries from dataset\n",
    "scodes_to_remove_ind = [x in missing for x in df.scode]\n",
    "df.drop(df.loc[scodes_to_remove_ind].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c716d9",
   "metadata": {
    "id": "996fca73"
   },
   "source": [
    "#### Create \"Target\" column and add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c0bf78a",
   "metadata": {
    "id": "3770fccb",
    "outputId": "923b88c5-6d8f-4a29-ad0e-8c6c0685812a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15207 entries, 0 to 15207\n",
      "Data columns (total 77 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   index                              15061 non-null  float64       \n",
      " 1   country                            15061 non-null  object        \n",
      " 2   scode                              15061 non-null  object        \n",
      " 3   region                             15061 non-null  object        \n",
      " 4   protestnumber                      15061 non-null  float64       \n",
      " 5   protesterviolence                  15061 non-null  float64       \n",
      " 6   startdate                          15061 non-null  datetime64[ns]\n",
      " 7   duration_days                      15061 non-null  float64       \n",
      " 8   participants                       15061 non-null  float64       \n",
      " 9   participants_category              15061 non-null  object        \n",
      " 10  demand_labor-wage-dispute          15061 non-null  float64       \n",
      " 11  demand_land-farm-issue             15061 non-null  float64       \n",
      " 12  demand_police-brutality            15061 non-null  float64       \n",
      " 13  demand_political-behavior/process  15061 non-null  float64       \n",
      " 14  demand_price-increases/tax-policy  15061 non-null  float64       \n",
      " 15  demand_removal-of-politician       15061 non-null  float64       \n",
      " 16  demand_social-restrictions         15061 non-null  float64       \n",
      " 17  year_scode                         15061 non-null  object        \n",
      " 18  system                             15061 non-null  object        \n",
      " 19  yrsoffc                            15061 non-null  float64       \n",
      " 20  finittrm                           15061 non-null  float64       \n",
      " 21  yrcurnt                            15061 non-null  float64       \n",
      " 22  termlimit                          15061 non-null  float64       \n",
      " 23  reelect                            15061 non-null  float64       \n",
      " 24  multpl                             15061 non-null  float64       \n",
      " 25  military                           15061 non-null  float64       \n",
      " 26  defmin                             15061 non-null  float64       \n",
      " 27  prtyin                             15061 non-null  float64       \n",
      " 28  execrlc                            15061 non-null  object        \n",
      " 29  execnat                            15061 non-null  float64       \n",
      " 30  execrel                            15061 non-null  object        \n",
      " 31  execage                            15061 non-null  float64       \n",
      " 32  allhouse                           15061 non-null  float64       \n",
      " 33  totalseats                         15061 non-null  float64       \n",
      " 34  oppmajh                            15061 non-null  float64       \n",
      " 35  oppmajs                            15061 non-null  float64       \n",
      " 36  legelec                            15061 non-null  float64       \n",
      " 37  exelec                             15061 non-null  float64       \n",
      " 38  liec                               15061 non-null  float64       \n",
      " 39  eiec                               15061 non-null  float64       \n",
      " 40  mdmh                               15061 non-null  float64       \n",
      " 41  mdms                               15061 non-null  float64       \n",
      " 42  ssh                                15061 non-null  float64       \n",
      " 43  pluralty                           15061 non-null  float64       \n",
      " 44  pr                                 15061 non-null  float64       \n",
      " 45  housesys                           15061 non-null  object        \n",
      " 46  sensys                             15061 non-null  object        \n",
      " 47  thresh                             15061 non-null  float64       \n",
      " 48  cl                                 15061 non-null  float64       \n",
      " 49  gq                                 15061 non-null  float64       \n",
      " 50  gqi                                15061 non-null  float64       \n",
      " 51  fraud                              15061 non-null  object        \n",
      " 52  auton                              15061 non-null  float64       \n",
      " 53  muni                               15061 non-null  float64       \n",
      " 54  state                              15061 non-null  float64       \n",
      " 55  author                             15061 non-null  float64       \n",
      " 56  numvote                            15061 non-null  float64       \n",
      " 57  oppvote                            15061 non-null  float64       \n",
      " 58  maj                                15061 non-null  float64       \n",
      " 59  partyage                           15061 non-null  float64       \n",
      " 60  herfgov                            15061 non-null  float64       \n",
      " 61  herfopp                            15061 non-null  float64       \n",
      " 62  frac                               15061 non-null  float64       \n",
      " 63  oppfrac                            15061 non-null  float64       \n",
      " 64  govfrac                            15061 non-null  float64       \n",
      " 65  tensys_strict                      15061 non-null  float64       \n",
      " 66  checks                             15061 non-null  float64       \n",
      " 67  stabs_strict                       15061 non-null  float64       \n",
      " 68  tenlong_strict                     15061 non-null  float64       \n",
      " 69  tenshort_strict                    15061 non-null  float64       \n",
      " 70  polariz                            15061 non-null  float64       \n",
      " 71  country_govt                       15061 non-null  object        \n",
      " 72  scode_govt                         15061 non-null  object        \n",
      " 73  percent                            15061 non-null  float64       \n",
      " 74  xconst                             15061 non-null  object        \n",
      " 75  next_regime_chg_date               15061 non-null  datetime64[ns]\n",
      " 76  days_until_next_regime_chg         15061 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(61), object(14)\n",
      "memory usage: 9.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Reimport in one location for easy QC as src file is updated\n",
    "target = create_target(df, df_regimes)\n",
    "df = pd.concat([df, target], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c7b0f4",
   "metadata": {
    "id": "1e5ecaf8"
   },
   "source": [
    "### Basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af79667",
   "metadata": {
    "id": "0653d30e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert startdate to a float instead of datetime since datetime \n",
    "# cannot be handled by models but fractional years can\n",
    "df['startdate'] = df.startdate.dt.year + \\\n",
    "                  df.startdate.dt.month/12 + \\\n",
    "                  df.startdate.dt.day/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31810836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Categorical datatypes\n",
    "df['region'] = df.region.astype('category')\n",
    "df['system'] = df.system.astype('category')\n",
    "df['country'] = df.country.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfcce4e",
   "metadata": {
    "id": "eeba02f1"
   },
   "source": [
    "##### Run custom function that removes all features that don't have a minimum threshold of non-null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b1a2ab",
   "metadata": {
    "id": "9a154d4f",
    "outputId": "82fdae63-9c75-43c7-9b31-ad6e65eb3501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14787 entries, 0 to 15060\n",
      "Data columns (total 34 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   index                              14787 non-null  float64       \n",
      " 1   country                            14787 non-null  category      \n",
      " 2   scode                              14787 non-null  object        \n",
      " 3   region                             14787 non-null  category      \n",
      " 4   protestnumber                      14787 non-null  float64       \n",
      " 5   protesterviolence                  14787 non-null  float64       \n",
      " 6   startdate                          14787 non-null  float64       \n",
      " 7   duration_days                      14787 non-null  float64       \n",
      " 8   participants                       14787 non-null  float64       \n",
      " 9   participants_category              14787 non-null  object        \n",
      " 10  demand_labor-wage-dispute          14787 non-null  float64       \n",
      " 11  demand_land-farm-issue             14787 non-null  float64       \n",
      " 12  demand_police-brutality            14787 non-null  float64       \n",
      " 13  demand_political-behavior/process  14787 non-null  float64       \n",
      " 14  demand_price-increases/tax-policy  14787 non-null  float64       \n",
      " 15  demand_removal-of-politician       14787 non-null  float64       \n",
      " 16  demand_social-restrictions         14787 non-null  float64       \n",
      " 17  year_scode                         14787 non-null  object        \n",
      " 18  system                             14787 non-null  category      \n",
      " 19  yrsoffc                            14787 non-null  float64       \n",
      " 20  military                           14787 non-null  float64       \n",
      " 21  totalseats                         14787 non-null  float64       \n",
      " 22  legelec                            14787 non-null  float64       \n",
      " 23  exelec                             14787 non-null  float64       \n",
      " 24  liec                               14787 non-null  float64       \n",
      " 25  eiec                               14787 non-null  float64       \n",
      " 26  numvote                            14787 non-null  float64       \n",
      " 27  oppvote                            14787 non-null  float64       \n",
      " 28  tensys_strict                      14787 non-null  float64       \n",
      " 29  country_govt                       14787 non-null  object        \n",
      " 30  scode_govt                         14787 non-null  object        \n",
      " 31  xconst                             14787 non-null  float64       \n",
      " 32  next_regime_chg_date               14787 non-null  datetime64[ns]\n",
      " 33  days_until_next_regime_chg         14787 non-null  float64       \n",
      "dtypes: category(3), datetime64[ns](1), float64(25), object(5)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = remove_missing_data(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff57a9b",
   "metadata": {
    "id": "9a31bc9a"
   },
   "source": [
    "# Modeling\n",
    "\n",
    "Given the cleaned and aggregated dataset above, the next section moves into the Modeling phase. Each model type is constructed using elements of encoding, scaling, resampling and hyperparameter optimization.\n",
    "\n",
    "- One hot encoding was essential given the categorical type of some features\n",
    "- Standard scaling was essential given the vast array of different numerical feature distributions and ranges. Min-max scaling was considered but proved less effective.\n",
    "- SMOTE was determined to be essential given the imbalanced nature of the dataset. Only 11% of the target feature values were 1, leaving the other 89% as 0. This is a prime example of the need for resampling, and SMOTE proved highly effective.\n",
    "- Hyperparameter grid searches are inherently valuable when optimizing a model. Appropriate hyperparameter searches were used for each model type.\n",
    "\n",
    "The output of each model is provided in terms of four core statistical measures (f1 score, accuracy, precision, and recall), in addition to displaying a confusion matrix for the test data. F1 was selected before the modeling process as the most relevant metric given that it encomasses all possible outcomes, as opposed to the other three metrics which leave out at least one possible outcome from their evaluation. \n",
    "\n",
    "Note that the final holdout dataset is not used for evaluation until the final model has been selected based on train-test data performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452b3e8",
   "metadata": {
    "id": "79155834"
   },
   "source": [
    "##### Define target\n",
    "\n",
    "\n",
    "This allows the user to define the target in terms of the number of days before which a regime transition will occur. For this analysis, it uses 365, but other values have also been explored with similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b509a355",
   "metadata": {
    "id": "64968105"
   },
   "outputs": [],
   "source": [
    "DAYS_UNTIL_CHG = 365\n",
    "target = pd.DataFrame(df['days_until_next_regime_chg'] < DAYS_UNTIL_CHG)\n",
    "target = target.astype('int')\n",
    "target.columns = ['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa1b1c",
   "metadata": {
    "id": "be9fabf4"
   },
   "source": [
    "##### Drop unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5427f8d",
   "metadata": {
    "id": "a172cd41",
    "outputId": "0e1ff1a8-f961-448a-d416-90193e900a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14787 entries, 0 to 15060\n",
      "Data columns (total 24 columns):\n",
      " #   Column                             Non-Null Count  Dtype   \n",
      "---  ------                             --------------  -----   \n",
      " 0   country                            14787 non-null  category\n",
      " 1   region                             14787 non-null  category\n",
      " 2   protestnumber                      14787 non-null  float64 \n",
      " 3   protesterviolence                  14787 non-null  float64 \n",
      " 4   participants                       14787 non-null  float64 \n",
      " 5   demand_labor-wage-dispute          14787 non-null  float64 \n",
      " 6   demand_land-farm-issue             14787 non-null  float64 \n",
      " 7   demand_police-brutality            14787 non-null  float64 \n",
      " 8   demand_political-behavior/process  14787 non-null  float64 \n",
      " 9   demand_price-increases/tax-policy  14787 non-null  float64 \n",
      " 10  demand_removal-of-politician       14787 non-null  float64 \n",
      " 11  demand_social-restrictions         14787 non-null  float64 \n",
      " 12  system                             14787 non-null  category\n",
      " 13  yrsoffc                            14787 non-null  float64 \n",
      " 14  military                           14787 non-null  float64 \n",
      " 15  totalseats                         14787 non-null  float64 \n",
      " 16  legelec                            14787 non-null  float64 \n",
      " 17  exelec                             14787 non-null  float64 \n",
      " 18  liec                               14787 non-null  float64 \n",
      " 19  eiec                               14787 non-null  float64 \n",
      " 20  numvote                            14787 non-null  float64 \n",
      " 21  oppvote                            14787 non-null  float64 \n",
      " 22  tensys_strict                      14787 non-null  float64 \n",
      " 23  xconst                             14787 non-null  float64 \n",
      "dtypes: category(3), float64(21)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "drop_cols = ['year_scode', 'scode_govt', 'country_govt', 'startdate',\n",
    "             'days_until_next_regime_chg', 'scode', 'participants_category', \n",
    "             'next_regime_chg_date', 'index', 'duration_days']\n",
    "\n",
    "model_inputs = df.drop(drop_cols, axis=1)\n",
    "model_inputs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9dc6df",
   "metadata": {},
   "source": [
    "### Identify multi-collinearity and remove features as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f89c005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collinearity_printout(df):\n",
    "    '''\n",
    "    SOURCE: FLATIRON 19.6 \"Multicollinearity of Features - Lab\"\n",
    "    https://github.com/learn-co-curriculum/dsc-multicollinearity-of-features-lab/tree/master\n",
    "\n",
    "    FUNCTIONALITY:\n",
    "    save absolute value of correlation matrix as a data frame\n",
    "    converts all values to absolute value\n",
    "    stacks the row:column pairs into a multindex\n",
    "    reset the index to set the multindex to seperate columns\n",
    "    sort values. 0 is the column automatically generated by the stacking\n",
    "    '''\n",
    "    \n",
    "    df_corr=df.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "    # zip the variable name columns (Which were only named level_0 and level_1 by default) in a new column named \"pairs\"\n",
    "    df_corr['pairs'] = list(zip(df_corr.level_0, df_corr.level_1))\n",
    "\n",
    "    # set index to pairs\n",
    "    df_corr.set_index(['pairs'], inplace = True)\n",
    "\n",
    "    #d rop level columns\n",
    "    df_corr.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "    # rename correlation column as cc rather than 0\n",
    "    df_corr.columns = ['cc']\n",
    "\n",
    "    # drop duplicates. This could be dangerous if you have variables perfectly correlated with variables other than themselves.\n",
    "    # for the sake of exercise, kept it in.\n",
    "    df_corr.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df_corr[(df_corr.cc<1.0) & (df_corr.cc>0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3328ac56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairs</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(liec, eiec)</th>\n",
       "      <td>0.731314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    cc\n",
       "pairs                 \n",
       "(liec, eiec)  0.731314"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collinearity_printout(model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c209631f",
   "metadata": {
    "id": "4ac5c1d4"
   },
   "source": [
    "##### Standard train-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f790ba9",
   "metadata": {
    "id": "8cac0b13"
   },
   "outputs": [],
   "source": [
    "x_traintest, x_holdout, y_traintest, y_holdout = train_test_split(model_inputs, \n",
    "                                                     target, \n",
    "                                                     random_state=RANDOM_STATE, \n",
    "                                                     test_size=0.3)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_traintest, \n",
    "                                                    y_traintest, \n",
    "                                                    random_state=RANDOM_STATE, \n",
    "                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6068c2f4",
   "metadata": {
    "id": "80b25649"
   },
   "source": [
    "### Define models and parameter grids\n",
    "\n",
    "Define all models and grids in one place. A pipeline structure is created such that each of these models can be run with the below-defined hyperparameter tuning grids alongside their resampling, scaling and encoding. This allows for minimal repetition in code and a consistent structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77c44e41",
   "metadata": {
    "id": "7fd54777"
   },
   "outputs": [],
   "source": [
    "# Set parameter grid to search across\n",
    "grid_bay = {'model__var_smoothing': [1e-9]}\n",
    "\n",
    "grid_log = {'model__C': np.logspace(-1, 5, 20)}\n",
    "\n",
    "grid_dt = {\n",
    "#     'model__max_depth': [3, 5, 7], \n",
    "#     'model__criterion': ['gini', 'entropy'],\n",
    "#     'model__min_samples_split': [5, 10],\n",
    "    'model__min_samples_leaf': [5, 10]} \n",
    "\n",
    "grid_rf = {\n",
    "#     'model__n_estimators': [25, 75, 150],\n",
    "#     'model__criterion': ['gini', 'entropy'],\n",
    "#     'model__max_depth': [3, 6, 10],\n",
    "#     'model__min_samples_split': [5, 10],\n",
    "    'model__min_samples_leaf': [3, 6]}\n",
    "\n",
    "grid_knn = {\n",
    "#     'model__leaf_size': [25, 50, 75],\n",
    "#     'model__n_neighbors': [3, 5, 7, 9],\n",
    "    'model__weights': ['uniform', 'distance']}      \n",
    "\n",
    "grid_ada = {\n",
    "#     'model__n_estimators': [50, 200],\n",
    "    'model__learning_rate': [0.1, 0.25, 1]}\n",
    "\n",
    "grid_xgb = {\n",
    "    'model__learning_rate': [0.01, 0.1, 0.25],\n",
    "    'model__max_depth': [6, 8, 10, 12],\n",
    "    'model__subsample': [0.4, 0.7, 1],\n",
    "    'model__n_estimators': [100, 200, 300, 400]}\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "model_bay = GaussianNB()\n",
    "model_log = LogisticRegression(max_iter=5000)\n",
    "model_dt = DecisionTreeClassifier()\n",
    "model_rf = RandomForestClassifier()\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_ada = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "model_xgb = XGBClassifier(eval_metric='logloss', use_label_encoder=False, \n",
    "                          random_state=RANDOM_STATE)\n",
    "\n",
    "grids = [grid_bay, grid_log, grid_dt, grid_rf, grid_knn, grid_ada, grid_xgb]\n",
    "models = [model_bay, model_log, model_dt, model_rf, model_knn, model_ada, model_xgb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ef765",
   "metadata": {
    "id": "f41abff2"
   },
   "source": [
    "#### Pipeline function\n",
    "\n",
    "This high-level function wraps all the different components of the model pipeline into one location, applying one-hot encoding, standard scaling, smote resampling, and grid searches to the input model. It also outputs performance in the form of standard metrics and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "330103e8",
   "metadata": {
    "id": "8d30a3d5"
   },
   "outputs": [],
   "source": [
    "def create_pipeline_and_run(model, grid, metric='accuracy'):\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    scaler = StandardScaler()\n",
    "    smote = SMOTE(random_state=RANDOM_STATE)\n",
    "\n",
    "    selector_object = make_column_selector(dtype_exclude='number')\n",
    "    selector_numeric = make_column_selector(dtype_include='number')\n",
    "    transformer = make_column_transformer((ohe, selector_object),\n",
    "                                         (scaler, selector_numeric))\n",
    "\n",
    "\n",
    "    pipe = Pipeline([('transformer', transformer),\n",
    "                     ('smote', smote), \n",
    "                     ('model', model)])\n",
    "\n",
    "    # Instantiate and fit grid search object\n",
    "    grid = GridSearchCV(pipe, grid, scoring='f1', cv=3)\n",
    "    grid.fit(x_train, y_train.values.ravel())\n",
    "    pred = grid.best_estimator_.predict(x_test)\n",
    "    \n",
    "    \n",
    "    print(f'{model}:')\n",
    "    print_scores(pred, y_test)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(grid.best_estimator_, x_test, y_test)\n",
    "    plt.show();\n",
    "    \n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5300981c",
   "metadata": {
    "id": "255b1de9"
   },
   "source": [
    "#### Dummy classifier as performance baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60ce1fdc",
   "metadata": {
    "id": "01b82066",
    "outputId": "38a433b4-87dc-475b-9fa5-0e0fefc3547f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUMMY SCORE (stratified):\n",
      "- f1: 0.08498583569405099\n",
      "- accuracy: 0.7919484702093398\n",
      "- precision: 0.08823529411764706\n",
      "- recall: 0.08196721311475409\n",
      "DUMMY SCORE (uniform):\n",
      "- f1: 0.20051948051948051\n",
      "- accuracy: 0.5043478260869565\n",
      "- precision: 0.12379730596536241\n",
      "- recall: 0.5273224043715847\n",
      "DUMMY SCORE (most_frequent):\n",
      "- f1: 0.0\n",
      "- accuracy: 0.8821256038647343\n",
      "- precision: 0.0\n",
      "- recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "for strategy in [\"stratified\", \"uniform\", \"most_frequent\"]:\n",
    "    dummy_clf = DummyClassifier(strategy=strategy)\n",
    "    dummy_clf.fit(x_train, y_train)\n",
    "    \n",
    "    print(f'DUMMY SCORE ({strategy}):')\n",
    "    pred = dummy_clf.predict(x_test)\n",
    "    print_scores(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ced5c0",
   "metadata": {
    "id": "1fc8d211"
   },
   "source": [
    "### Run *all models* defined above\n",
    "\n",
    "Run this cell to output the performance of all above-defined models in one place for a side-by-side comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c313415",
   "metadata": {
    "id": "28881aff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pipes = []\n",
    "# for grid, model in zip(grids, models):\n",
    "#     pipe = create_pipeline_and_run(model, grid)\n",
    "#     pipes.append(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4376b24e",
   "metadata": {
    "id": "39e01b75",
    "tags": []
   },
   "source": [
    "### Run *only one* model\n",
    "\n",
    "Choose which model to run in the below cell (used for iterative testing and investigating model specifics without running all models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348537d",
   "metadata": {
    "id": "1e1992d0",
    "outputId": "8d897dc6-8825-4b09-86ee-4710b794c22b"
   },
   "outputs": [],
   "source": [
    "# xgb = pipes[-1] # Since it is the last model in pipes\n",
    "\n",
    "# Uncomment and run to look at one model separately\n",
    "xgb = create_pipeline_and_run(model_xgb, grid_xgb);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738c9b6",
   "metadata": {},
   "source": [
    "##### Print optimal model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5983acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgb.steps[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf0f20",
   "metadata": {
    "id": "aac309ba"
   },
   "source": [
    "#### Test model on holdout dataset\n",
    "\n",
    "XG bosst proves to be the highest performing model. Test its performance on the holdout dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9071079a",
   "metadata": {
    "id": "321e43a2",
    "outputId": "319c2526-d622-42c0-ab73-5438a3f69913"
   },
   "outputs": [],
   "source": [
    "# Predict output\n",
    "pred = xgb.predict(x_holdout)\n",
    "\n",
    "# Show performance\n",
    "print_scores(pred, y_holdout)\n",
    "plot_confusion_matrix(xgb, x_holdout, y_holdout);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d159348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict output\n",
    "pred = xgb.predict(x_holdout)\n",
    "\n",
    "# Show performance\n",
    "print_scores(pred, y_holdout)\n",
    "\n",
    "# Plot test data and full data performance\n",
    "labels = ['No change', 'Regime Change']\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,8))\n",
    "plt.subplots_adjust(wspace=0.6, hspace=None)\n",
    "axes[0].set_title('Holdout Dataset (%)')\n",
    "axes[1].set_title('Entire Dataset (%)')\n",
    "\n",
    "plot_confusion_matrix(xgb, x_holdout, y_holdout, ax=axes[0], display_labels=labels, colorbar=False, normalize='all')\n",
    "plot_confusion_matrix(xgb, model_inputs, target, ax=axes[1], display_labels=labels, colorbar=False, normalize='all');\n",
    "\n",
    "plt.savefig('../images/confusion_matrices.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d956f",
   "metadata": {
    "id": "f6c64cee"
   },
   "source": [
    "### Feature importance\n",
    "\n",
    "Evaluate the feature importance in the top-performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269c06e6",
   "metadata": {
    "id": "901dd0a6",
    "outputId": "67b7f70f-0da4-4908-8efb-bfe137d72397"
   },
   "outputs": [],
   "source": [
    "# SHAP summary plot for XGB\n",
    "produce_shap_plot(x_train, y_train, x_test, y_test, clone(xgb), \n",
    "                  title='Feature Importance Summary Plot for XGB Model', \n",
    "                  savepath = '../images/shap_summary_plot.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb1845",
   "metadata": {
    "id": "463c92ab",
    "outputId": "8ed67227-ef49-402a-e703-5dd18f5e395b"
   },
   "outputs": [],
   "source": [
    "# SHAP bar plot for XGB model\n",
    "model = xgb.steps[2][1]\n",
    "x_train_final, y_train_final, df_test_expanded_scaled = get_shap_df(x_train, \n",
    "                                                                    y_train, \n",
    "                                                                    x_test)\n",
    "model.fit(x_train_final, y_train_final)\n",
    "explainer = shap.Explainer(model)\n",
    "plt.title('Feature Importance for XGB Model')\n",
    "shap_values = explainer(df_test_expanded_scaled)\n",
    "shap.plots.bar(shap_values, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf6b5d6",
   "metadata": {
    "id": "b6237e37",
    "outputId": "b6a4fc07-be20-4110-ff06-d73519f2a71d"
   },
   "outputs": [],
   "source": [
    "# Source: \n",
    "# shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/bar.html\n",
    "plt.title('Feature Importance for XGB Model')\n",
    "shap.plots.bar(shap_values.cohorts(2).abs.mean(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dfb71b",
   "metadata": {},
   "source": [
    "### Permutation Feature Importance\n",
    "\n",
    "Source: https://scikit-learn.org/stable/modules/permutation_importance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79748c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.steps[2][1]\n",
    "x_tr, y_tr, x_te = get_shap_df(x_train, y_train, x_test)\n",
    "model.fit(x_tr, y_tr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: FLATIRON 19.6 \"Multicollinearity of Features - Lab\"\n",
    "# https://github.com/learn-co-curriculum/dsc-multicollinearity-of-features-lab/tree/master\n",
    "\n",
    "# save absolute value of correlation matrix as a data frame\n",
    "# converts all values to absolute value\n",
    "# stacks the row:column pairs into a multindex\n",
    "# reset the index to set the multindex to seperate columns\n",
    "# sort values. 0 is the column automatically generated by the stacking\n",
    "\n",
    "df_corr=model_inputs.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "# zip the variable name columns (Which were only named level_0 and level_1 by default) in a new column named \"pairs\"\n",
    "df_corr['pairs'] = list(zip(df_corr.level_0, df_corr.level_1))\n",
    "\n",
    "# set index to pairs\n",
    "df_corr.set_index(['pairs'], inplace = True)\n",
    "\n",
    "#d rop level columns\n",
    "df_corr.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# rename correlation column as cc rather than 0\n",
    "df_corr.columns = ['cc']\n",
    "\n",
    "# drop duplicates. This could be dangerous if you have variables perfectly correlated with variables other than themselves.\n",
    "# for the sake of exercise, kept it in.\n",
    "df_corr.drop_duplicates(inplace=True)\n",
    "\n",
    "df_corr[(df_corr.cc>0.99)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://scikit-learn.org/stable/modules/permutation_importance.html\n",
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(model, x_te, y_test, n_repeats=30, random_state=RANDOM_STATE)\n",
    "\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 0 * r.importances_std[i] > 0:\n",
    "        #print(f\"{df_train.feature_names[i]:<8}\"\n",
    "        print(f\"{x_tr.columns[i]} \"\n",
    "              f\"{r.importances_mean[i]:.3f}\"\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792fbc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.importances_mean.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190cefb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs.loc[(model_inputs.parreg==1)].parcomp.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b6d03",
   "metadata": {
    "id": "5487d30b"
   },
   "source": [
    "## Export to SQL\n",
    "\n",
    "Export data for analysis in separate EDA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ed56ab",
   "metadata": {
    "id": "bb358ec3"
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../data/processed/all_data.db')\n",
    "\n",
    "model_data = pd.concat([model_inputs, target], axis=1)\n",
    "\n",
    "with engine.begin() as connection:\n",
    "    model_data.to_sql(name='all_modeled_data', \n",
    "                      con=connection, \n",
    "                      if_exists='replace', \n",
    "                      index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MODEL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
