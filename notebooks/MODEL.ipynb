{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c17f7b65",
   "metadata": {
    "id": "818646af"
   },
   "source": [
    "# Modeling\n",
    "\n",
    "This notebook combines the three cleaned datasets into one central location and aggregates them before conducting data engineering and running a wide array of models to determine the final top performer and understand the relationships between the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e38aac",
   "metadata": {
    "id": "9ba85793"
   },
   "source": [
    "## Data Imporrts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6bf1a",
   "metadata": {
    "id": "8b5bb73c"
   },
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Importing databases using SQL\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Model preprocessing and processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Performance evaluation\n",
    "from sklearn.metrics import f1_score,precision_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# Data visualization\n",
    "import shap\n",
    "\n",
    "# Options\n",
    "#pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 200\n",
    "%matplotlib inline\n",
    "\n",
    "# Convenience for working with external src code files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "# Custom functions\n",
    "from create_target import *\n",
    "from remove_missing_data import *\n",
    "from evaluate_model_performance import *\n",
    "from custom_plots import *\n",
    "\n",
    "# Global constants\n",
    "RANDOM_STATE = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e475b",
   "metadata": {
    "id": "393ddbf1"
   },
   "source": [
    "##### Import \"Protests\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f7999",
   "metadata": {
    "id": "fdd60fdd"
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../data/processed/protests.db')\n",
    "with engine.begin() as connection:\n",
    "    df_protests = pd.read_sql('SELECT * FROM protests', con=connection)\n",
    "\n",
    "# Type casting\n",
    "df_protests.startdate = pd.to_datetime(df_protests.startdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb908b",
   "metadata": {
    "id": "768bda6c"
   },
   "source": [
    "##### Import \"Governments\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f407f3d2",
   "metadata": {
    "id": "712c9b25"
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../data/processed/governments.db')\n",
    "with engine.begin() as connection:\n",
    "    df_govts = pd.read_sql('SELECT * FROM governments', con=connection)\n",
    "\n",
    "# Set index to be used on Join later\n",
    "df_govts.index = df_govts.year_scode\n",
    "\n",
    "# Remove unused features\n",
    "df_govts.drop('year_scode', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde229a",
   "metadata": {
    "id": "feecd926"
   },
   "source": [
    "##### Join \"Protests\" and \"Governments\" datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b31acc",
   "metadata": {
    "id": "8f56d152"
   },
   "outputs": [],
   "source": [
    "# Join both dataframes\n",
    "df = df_protests.join(df_govts, how='left', on='year_scode')\n",
    "\n",
    "# Remove entries that don't have corresponding 'government' data\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0e94e",
   "metadata": {
    "id": "68adfe35"
   },
   "source": [
    "##### Import \"Regime Changes\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd3861",
   "metadata": {
    "id": "7473f360",
    "outputId": "1c0d60ac-2556-48f1-86a9-7ae46e1446b1"
   },
   "outputs": [],
   "source": [
    "# IMPORT REGIME CHANGE DATASET\n",
    "engine = create_engine('sqlite:///../data/processed/regime_changes.db')\n",
    "with engine.begin() as connection:\n",
    "    df_regimes = pd.read_sql('SELECT * FROM regime_changes', con=connection)\n",
    "\n",
    "# Type conversions\n",
    "df_regimes.startdate = pd.to_datetime(df_regimes.startdate)\n",
    "df_regimes.enddate = pd.to_datetime(df_regimes.enddate)\n",
    "df_regimes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d66814",
   "metadata": {
    "id": "309fd063"
   },
   "source": [
    "##### QC that country names and country IDs match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff45c7",
   "metadata": {
    "id": "e9fe039d",
    "outputId": "e404a394-1a3c-4650-efdf-e0b25a5f6641"
   },
   "outputs": [],
   "source": [
    "cols = ['scode', 'scode_govt', 'country', 'country_govt']\n",
    "missing_countries = df.loc[(df.country != df.country_govt)][cols]\n",
    "missing_countries = missing_countries.drop_duplicates()\n",
    "display(missing_countries.sort_values(by='scode'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e6a61",
   "metadata": {
    "id": "3c1bbefe"
   },
   "source": [
    "##### Remove countries that do not contain government data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c24a6",
   "metadata": {
    "id": "2d33149d"
   },
   "outputs": [],
   "source": [
    "scodes_to_remove = missing_countries.scode.unique()\n",
    "scodes_to_remove_ind = [x in scodes_to_remove for x in df.scode]\n",
    "df.drop(df.loc[scodes_to_remove_ind].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93496dbb",
   "metadata": {
    "id": "13aafc6d"
   },
   "source": [
    "##### Identify countries that are missing from \"Regime Changes\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ec59c",
   "metadata": {
    "id": "fcc6d52f",
    "outputId": "9b33c1b8-65b3-49cd-a12d-169c825c3a60"
   },
   "outputs": [],
   "source": [
    "# All countries in union of Protests and Governments\n",
    "all_countries = df.scode.unique()\n",
    "\n",
    "# All countries in Regimes\n",
    "regime_countries = df_regimes.scode.unique()\n",
    "\n",
    "\n",
    "# Loop over all_countries\n",
    "missing = []\n",
    "for country in all_countries:\n",
    "    # Make note of any countries not in Regimes\n",
    "    \n",
    "    if country not in regime_countries:\n",
    "        missing.append(country)\n",
    "\n",
    "print('Countries missing from \"Regimes\" dataset:', missing)\n",
    "\n",
    "# Remove these countries from dataset\n",
    "scodes_to_remove_ind = [x in missing for x in df.scode]\n",
    "df.drop(df.loc[scodes_to_remove_ind].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd23f9",
   "metadata": {
    "id": "996fca73"
   },
   "source": [
    "#### Create \"Target\" column and add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d7a85",
   "metadata": {
    "id": "3770fccb",
    "outputId": "923b88c5-6d8f-4a29-ad0e-8c6c0685812a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reimport in one location for easy QC as src file is updated\n",
    "target = create_target(df, df_regimes)\n",
    "df = pd.concat([df, target], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a3443e",
   "metadata": {
    "id": "1e5ecaf8"
   },
   "source": [
    "### Basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa99d08",
   "metadata": {
    "id": "0653d30e"
   },
   "outputs": [],
   "source": [
    "# Convert startdate to a float instead of datetime since datetime \n",
    "# cannot be handled by models but fractional years can\n",
    "df['startdate'] = df.startdate.dt.year + \\\n",
    "                  df.startdate.dt.month/12 + \\\n",
    "                  df.startdate.dt.day/365"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108d9b1",
   "metadata": {
    "id": "eeba02f1"
   },
   "source": [
    "##### Run custom function that removes all features that don't have a minimum threshold of non-null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2cf1ee",
   "metadata": {
    "id": "9a154d4f",
    "outputId": "82fdae63-9c75-43c7-9b31-ad6e65eb3501"
   },
   "outputs": [],
   "source": [
    "df = remove_missing_data(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f5c3d5",
   "metadata": {
    "id": "9a31bc9a"
   },
   "source": [
    "# Modeling\n",
    "\n",
    "Given the cleaned and aggregated dataset above, the next section moves into the Modeling phase. Each model type is constructed using elements of encoding, scaling, resampling and hyperparameter optimization.\n",
    "\n",
    "- One hot encoding was essential given the categorical type of some features\n",
    "- Standard scaling was essential given the vast array of different numerical feature distributions and ranges. Min-max scaling was considered but proved less effective.\n",
    "- SMOTE was determined to be essential given the imbalanced nature of the dataset. Only 11% of the target feature values were 1, leaving the other 89% as 0. This is a prime example of the need for resampling, and SMOTE proved highly effective.\n",
    "- Hyperparameter grid searches are inherently valuable when optimizing a model. Appropriate hyperparameter searches were used for each model type.\n",
    "\n",
    "The output of each model is provided in terms of four core statistical measures (f1 score, accuracy, precision, and recall), in addition to displaying a confusion matrix for the test data. F1 was selected before the modeling process as the most relevant metric given that it encomasses all possible outcomes, as opposed to the other three metrics which leave out at least one possible outcome from their evaluation. \n",
    "\n",
    "Note that the final holdout dataset is not used for evaluation until the final model has been selected based on train-test data performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096d49ba",
   "metadata": {
    "id": "79155834"
   },
   "source": [
    "##### Define target\n",
    "\n",
    "\n",
    "This allows the user to define the target in terms of the number of days before which a regime transition will occur. For this analysis, it uses 365, but other values have also been explored with similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcde13f",
   "metadata": {
    "id": "64968105"
   },
   "outputs": [],
   "source": [
    "DAYS_UNTIL_CHG = 365\n",
    "target = pd.DataFrame(df['days_until_next_regime_chg'] < DAYS_UNTIL_CHG)\n",
    "target = target.astype('int')\n",
    "target.columns = ['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d44d5",
   "metadata": {
    "id": "be9fabf4"
   },
   "source": [
    "##### Drop unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba5872",
   "metadata": {
    "id": "a172cd41",
    "outputId": "0e1ff1a8-f961-448a-d416-90193e900a21"
   },
   "outputs": [],
   "source": [
    "drop_cols = ['year_scode', 'scode_govt', 'country_govt', \n",
    "             'days_until_next_regime_chg', 'scode', 'participants_category', \n",
    "             'next_regime_chg_date', 'index', 'duration_days']\n",
    "model_inputs = df.drop(drop_cols, axis=1)\n",
    "model_inputs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cdc6bc",
   "metadata": {
    "id": "4ac5c1d4"
   },
   "source": [
    "##### Standard train-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa5d4a8",
   "metadata": {
    "id": "8cac0b13"
   },
   "outputs": [],
   "source": [
    "x_traintest, x_holdout, y_traintest, y_holdout = train_test_split(model_inputs, \n",
    "                                                     target, \n",
    "                                                     random_state=RANDOM_STATE, \n",
    "                                                     test_size=0.3)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_traintest, \n",
    "                                                    y_traintest, \n",
    "                                                    random_state=RANDOM_STATE, \n",
    "                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ff6a3",
   "metadata": {
    "id": "80b25649"
   },
   "source": [
    "### Define models and parameter grids\n",
    "\n",
    "Define all models and grids in one place. A pipeline structure is created such that each of these models can be run with the below-defined hyperparameter tuning grids alongside their resampling, scaling and encoding. This allows for minimal repetition in code and a consistent structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499826d",
   "metadata": {
    "id": "7fd54777"
   },
   "outputs": [],
   "source": [
    "# Set parameter grid to search across\n",
    "grid_bay = {'model__var_smoothing': [1e-9]}\n",
    "\n",
    "grid_log = {'model__C': np.logspace(-1, 5, 20)}\n",
    "\n",
    "grid_dt = {\n",
    "    'model__max_depth': [3, 5, 7], \n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__min_samples_split': [5, 10],\n",
    "    'model__min_samples_leaf': [5, 10]} \n",
    "\n",
    "grid_rf = {\n",
    "    'model__n_estimators': [25, 75],#, 150],\n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__max_depth': [3, 7],# [3, 6, 10],\n",
    "    'model__min_samples_split': [5, 10],\n",
    "    'model__min_samples_leaf': [3, 6]}\n",
    "\n",
    "grid_knn = {\n",
    "    'model__leaf_size': [25, 50, 75],\n",
    "    'model__n_neighbors': [3, 5, 7, 9]}#,\n",
    "    'model__weights': ['uniform', 'distance']}      \n",
    "\n",
    "grid_ada = {\n",
    "    'model__n_estimators': [50, 200],\n",
    "    'model__learning_rate': [0.1, 0.25, 1]}\n",
    "\n",
    "grid_xgb = {\n",
    "    'model__learning_rate': [0.1, 0.25, 1],\n",
    "    'model__max_depth': [3, 5, 7, None],\n",
    "    'model__min_child_weight': [1, 2, None],\n",
    "    'model__subsample': [0.4, 0.6, 0.8, 1],\n",
    "    'model__n_estimators': [50, 100, 150, 200, 250],\n",
    "    'model__tree_method': ['exact', 'approx', 'hist']}\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "model_bay = GaussianNB()\n",
    "model_log = LogisticRegression(max_iter=5000)\n",
    "model_dt = DecisionTreeClassifier()\n",
    "model_rf = RandomForestClassifier()\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_ada = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "model_xgb = XGBClassifier(eval_metric='logloss', use_label_encoder=False, \n",
    "                          random_state=RANDOM_STATE)\n",
    "\n",
    "grids = [grid_bay, grid_log, grid_dt, grid_rf, grid_knn, grid_ada, grid_xgb]\n",
    "models = [model_bay, model_log, model_dt, model_rf, model_knn, model_ada, model_xgb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95e8b5",
   "metadata": {
    "id": "f41abff2"
   },
   "source": [
    "#### Pipeline function\n",
    "\n",
    "This high-level function wraps all the different components of the model pipeline into one location, applying one-hot encoding, standard scaling, smote resampling, and grid searches to the input model. It also outputs performance in the form of standard metrics and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77873e4",
   "metadata": {
    "id": "8d30a3d5"
   },
   "outputs": [],
   "source": [
    "def create_pipeline_and_run(model, grid, metric='accuracy'):\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    scaler = StandardScaler()\n",
    "    smote = SMOTE(random_state=RANDOM_STATE)\n",
    "\n",
    "    selector_object = make_column_selector(dtype_include='object')\n",
    "    selector_numeric = make_column_selector(dtype_include='number')\n",
    "    transformer = make_column_transformer((ohe, selector_object),\n",
    "                                         (scaler, selector_numeric))\n",
    "\n",
    "\n",
    "    pipe = Pipeline([('transformer', transformer),\n",
    "                     ('smote', smote), \n",
    "                     ('model', model)])\n",
    "\n",
    "    # Instantiate and fit grid search object\n",
    "    grid = GridSearchCV(pipe, grid, scoring='f1', cv=3)\n",
    "    grid.fit(x_train, y_train.values.ravel())\n",
    "    pred = grid.best_estimator_.predict(x_test)\n",
    "    \n",
    "    \n",
    "    print(f'{model}:')\n",
    "    print_scores(pred, y_test)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(grid.best_estimator_, x_test, y_test)\n",
    "    plt.show();\n",
    "    \n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf24b90",
   "metadata": {
    "id": "255b1de9"
   },
   "source": [
    "#### Dummy classifier as performance baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5d66d5",
   "metadata": {
    "id": "01b82066",
    "outputId": "38a433b4-87dc-475b-9fa5-0e0fefc3547f"
   },
   "outputs": [],
   "source": [
    "for strategy in [\"stratified\", \"uniform\", \"most_frequent\"]:\n",
    "    dummy_clf = DummyClassifier(strategy=strategy)\n",
    "    dummy_clf.fit(x_train, y_train)\n",
    "    \n",
    "    print(f'DUMMY SCORE ({strategy}):')\n",
    "    pred = dummy_clf.predict(x_test)\n",
    "    print_scores(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fbab5e",
   "metadata": {
    "id": "1fc8d211"
   },
   "source": [
    "### Run *all models* defined above\n",
    "\n",
    "Run this cell to output the performance of all above-defined models in one place for a side-by-side comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71292c9a",
   "metadata": {
    "id": "28881aff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipes = []\n",
    "for grid, model in zip(grids, models):\n",
    "    pipe = create_pipeline_and_run(model, grid)\n",
    "    pipes.append(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b73ca",
   "metadata": {
    "id": "39e01b75",
    "tags": []
   },
   "source": [
    "### Run *only one* model\n",
    "\n",
    "Choose which model to run in the below cell (used for iterative testing and investigating model specifics without running all models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc72d5",
   "metadata": {
    "id": "1e1992d0",
    "outputId": "8d897dc6-8825-4b09-86ee-4710b794c22b"
   },
   "outputs": [],
   "source": [
    "xgb = pipes[-1] # Since it is the last model in pipes\n",
    "\n",
    "# Uncomment and run to look at one model separately\n",
    "# xgb = create_pipeline_and_run(model_xgb, grid_xgb);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8128dc3",
   "metadata": {
    "id": "aac309ba"
   },
   "source": [
    "#### Test model on holdout dataset\n",
    "\n",
    "XG bosst proves to be the highest performing model. Test its performance on the holdout dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf4396",
   "metadata": {
    "id": "321e43a2",
    "outputId": "319c2526-d622-42c0-ab73-5438a3f69913"
   },
   "outputs": [],
   "source": [
    "# Predict output\n",
    "pred = xgb.predict(x_holdout)\n",
    "\n",
    "# Show performance\n",
    "print_scores(pred, y_holdout)\n",
    "plot_confusion_matrix(xgb, x_holdout, y_holdout);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict output\n",
    "pred = xgb.predict(x_holdout)\n",
    "\n",
    "# Show performance\n",
    "print_scores(pred, y_holdout)\n",
    "\n",
    "# Plot test data and full data performance\n",
    "labels = ['No change', 'Regime Change']\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,8))\n",
    "plt.subplots_adjust(wspace=0.6, hspace=None)\n",
    "axes[0].set_title('Holdout Dataset (%)')\n",
    "axes[1].set_title('Entire Dataset (%)')\n",
    "\n",
    "plot_confusion_matrix(xgb, x_holdout, y_holdout, ax=axes[0], display_labels=labels, colorbar=False, normalize='all')\n",
    "plot_confusion_matrix(xgb, model_inputs, target, ax=axes[1], display_labels=labels, colorbar=False, normalize='all');\n",
    "\n",
    "plt.savefig('../images/confusion_matrices.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb1d30",
   "metadata": {
    "id": "f6c64cee"
   },
   "source": [
    "### Feature importance\n",
    "\n",
    "Evaluate the feature importance in the top-performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17e477",
   "metadata": {
    "id": "901dd0a6",
    "outputId": "67b7f70f-0da4-4908-8efb-bfe137d72397"
   },
   "outputs": [],
   "source": [
    "# SHAP summary plot for XGB\n",
    "produce_shap_plot(x_train, y_train, x_test, y_test, clone(xgb), \n",
    "                  title='Feature Importance Summary Plot for XGB Model', \n",
    "                  savepath = '../images/shap_summary_plot.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d0a53",
   "metadata": {
    "id": "463c92ab",
    "outputId": "8ed67227-ef49-402a-e703-5dd18f5e395b"
   },
   "outputs": [],
   "source": [
    "# SHAP bar plot for XGB model\n",
    "model = xgb.steps[2][1]\n",
    "x_train_final, y_train_final, df_test_expanded_scaled = get_shap_df(x_train, \n",
    "                                                                    y_train, \n",
    "                                                                    x_test)\n",
    "\n",
    "explainer = shap.Explainer(model)\n",
    "plt.title('Feature Importance for XGB Model')\n",
    "shap_values = explainer(df_test_expanded_scaled)\n",
    "shap.plots.bar(shap_values, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c78fd",
   "metadata": {
    "id": "b6237e37",
    "outputId": "b6a4fc07-be20-4110-ff06-d73519f2a71d"
   },
   "outputs": [],
   "source": [
    "# Source: \n",
    "# shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/bar.html\n",
    "plt.title('Feature Importance for XGB Model')\n",
    "shap.plots.bar(shap_values.cohorts(2).abs.mean(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae10532",
   "metadata": {
    "id": "5487d30b"
   },
   "source": [
    "## Export to SQL\n",
    "\n",
    "Export data for analysis in separate EDA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0eccd0",
   "metadata": {
    "id": "bb358ec3"
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../data/processed/all_data.db')\n",
    "\n",
    "model_data = pd.concat([model_inputs, target], axis=1)\n",
    "\n",
    "with engine.begin() as connection:\n",
    "    model_data.to_sql(name='all_modeled_data', \n",
    "                      con=connection, \n",
    "                      if_exists='replace', \n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b0038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "MODEL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
